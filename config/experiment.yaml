env:
  type: rec_env
  params:
    cold_start: 10
    max_steps: 30
    top_k: 6

response_simulator:
  # type: random # 또는 llm
  # params: {}
  type: random
  # params:
  #   # 시뮬레이션 페르소나 설정 (1-100중 선택, null이면 랜덤)
  #   persona_id: 5
  #   # 페르소나 및 LLM 응답 정보 출력 여부
  #   debug: true
  #   # LLM 클라이언트 설정 (LLMResponseSimulator 사용 시에만 필요)
  #   llm_simulator:
  #     params:
  #       ollama_url: "http://localhost:11434"
  #       model: "llama3.2:3b-instruct-q4_K_M"
  #       debug: true

agent:
  type: dqn
  params:
    lr: 0.001
    batch_size: 32
    eps_start: 1.0
    eps_min: 0.05
    eps_decay: 0.995
    gamma: 0.99
    update_freq: 100

embedder:
  type: simple_concat
  params:
    user_embedder:
      type: simple_user
      params:
        user_dim: 30
    content_embedder:
      type: simple_content
      params:
        content_dim: 5

candidate_generator:
  type: query
  params:
    max_count_by_content: 24

reward_fn:
  type: default
  params: {}

experiment:
  total_episodes: 20
  max_recommendations: 6
  seeds: [0]
  result_log_path: "./data/experiment_results.log"

replay:
  capacity: 10000